
=====================================
Ceph 파일 시스템 클라이언트 쫓아내기eviction
=====================================

파일 시스템의 클라이언트가 응답하지 않거나 지시에 따르지 않는 경우 그
클라이언트를 파일 시스템에 접근하는 것을 강제로 종료시켜야 할 수도 있습니다.
이 과정을 쫓아내기eviction이라고 부릅니다. 

CephFS 클라이언트를 쫓아내는 것은 클라이언트가 더 이상 MDS 나 OSD와 통신하는
것을 막습니다. 클라이언트가 파일시스템에 buffered IO를 하고 있었다면, flush
되지 않은 데이터는 잃어버리게 됩니다. 

클라이언트는 (MDS와 재빠르게 통신하지 못할 경우) 자동으로 쫓겨나거나, (시스템
관리자에 의해) 수동으로 쫓겨날 수 있습니다.

클라이언트를 쫓아내는 과정은 모든 종류의 클라이언트에 적용됩니다. 이것은 FUSE
마운트, 커널 마운트, nfs-ganesha 게이트웨어, 그리고 libcephfs 를 사용하는 모든
프로세스를 포함합니다. 

자동으로 클라이언트를 쫓아내기
==============================

클라이언트가 자동으로 쫓겨나는 이유에는 세 가지 경우가 있습니다. 

#. 활성 상태의 MDS 데몬에 클라이언트가 MDS와 ``session_autoclose`` (파일 시스템
   변수) 초 (300초가 기본 설정) 동안 통신하지 않으면, 그 클라이언트는 자동으로
   쫓겨납니다.

#. 활성 상태의 MDS 데몬에 클라이언트가 cap revoke 메세지에
   ``mds_cap_revoke_eviction_timeout`` (설정 옵션) 초 동안 응답하지 않은 경우.
   이것은 기본적으로는 비활성화 되어 있습니다.

#. MDS 가 시작하는 동안 (failover 포함), MDS는 ``reconnect`` 라고 불리는 상태를
   통과합니다. 이 상태에 있을 때, MDS는 모든 클라이언트가 새로운 MDS 데몬에
   연결하기를 기다립니다. 만약 어떤 클라이언트든 정해진 시간 안에
   (``mds_reconnect_timeout``, 45초가 기본 값) 연결하지 못한다면, 그
   클라이언트들은 쫓겨날 것입니다. 

위와 같은 상황이 발생한다면 warning 메시지가 클러스터 로그에 표시됩니다.

수동으로 클라이언트를 쫓아내기
===============================

가끔 관리자는 어떤 클라이언트를 수동으로 쫓아내고 싶을 수 있습니다. 이것은
클라이언트가 죽었고 관리자는 그 클라이언트의 세션이 타임아웃 될 때 까지
기다리고 싶지 않을 때, 또는 클라이언트가 지시에 따르지 않지만, 관리자는
클라이언트 노드에서 unmount를 실행할 접근 권한이 없을 때 발생할 수 있습니다. 

먼저 클라이언트의 목록을 살펴보는 것이 유용합니다.

::

    ceph tell mds.0 client ls

    [
        {
            "id": 4305,
            "num_leases": 0,
            "num_caps": 3,
            "state": "open",
            "replay_requests": 0,
            "completed_requests": 0,
            "reconnecting": false,
            "inst": "client.4305 172.21.9.34:0/422650892",
            "client_metadata": {
                "ceph_sha1": "ae81e49d369875ac8b569ff3e3c456a31b8f3af5",
                "ceph_version": "ceph version 12.0.0-1934-gae81e49 (ae81e49d369875ac8b569ff3e3c456a31b8f3af5)",
                "entity_id": "0",
                "hostname": "senta04",
                "mount_point": "/tmp/tmpcMpF1b/mnt.0",
                "pid": "29377",
                "root": "/"
            }
        }
    ]
    

일단 쫓아내고자 하는 클라이언트를 찾아냈다면, unique ID 또는 다른 속성들을 
이용해서 그 클라이언트를 찾을 수 있습니다.

::
    
    # 아래 명령어는 모두 작동합니다
    ceph tell mds.0 client evict id=4305
    ceph tell mds.0 client evict client_metadata.=4305

고급: 클라이언트를 블랙리스트에서 제외하기
==========================================

보통은 블랙리스트에 추가된 클라이언트는 서버로 재접속하지 못합니다. 
그 클라이언트는 반드시 마운트 해제 후 다시 마운트되어야 합니다. 

하지만 어떤 상황에서는 쫓겨난 클라이언트가 다시 접속을 시도하게 허용하는 것이 유용할 수 있습니다.

CephFS는 RADOS OSD의 블랙리스트를 이용하여 클라이언트 쫓아내기를 설정하므로, 
CephFS의 클라이언트들을 블랙리스트에서 제거하면 그 클라이언트들은 다시 접속할 수 있습니다.

::

    $ ceph osd blacklist ls
    listed 1 entries
    127.0.0.1:0/3710147553 2018-03-19 11:32:24.716146
    $ ceph osd blacklist rm 127.0.0.1:0/3710147553
    un-blacklisting 127.0.0.1:0/3710147553


이렇게 하는 것은 블랙리스트에 들어간 클라이언트들이 buffered IO를 하고 있던
파일에 다른 클라이언트들이 접근했을 경우 데이터 정합성에 문제를 일으킬 수
있습니다.  또한 클라이언트가 완전히 정상적으로 동작할 것이라는 보장이 없습니다.
쫓겨난 이후 완전히 정상적인 클라이언트가 되는 방법은 마운트를 해제한 후, 새롭게
다시 마운트를 하는 것입니다.

만약 이 방법으로 클라이언트가 재접속하게 한다면, FUSE 클라이언트에서
``client_reconnect_stale`` 을 true로 해서 그 클라이언트가 재접속 하도록
물어보는 것이 유용할 것입니다. 

고급: 블랙리스트 설정
=======================

만약, 클라이언트의 호스트가 느리거나 불안정한 네트워크 때문에 클라이언트가 빈번하게 
쫓겨나고 있고, 근원적인 문제를 해결할 수 없는 상황이라면, MDS에게 덜 까다롭게 해 달라고 
말할 수 있습니다. 

느린 클라이언트에게 단순히 MDS 세션을 끊어버리지만, 그들이 다시 세션을 열고 
OSD와 대화하게 허용할 수 있습니다. 
이렇게 하기 위해서는 MDS 노드에서 ``mds_session_blacklist_on_timeout`` 를 false로 하면 딥니다. 

수동으로 쫓아낼 때에도 같은 방식으로 처리하게 하려면 ``mds_session_blacklist_on_evict`` 를 false로
하면 됩니다.

블랙리스팅이 비활성화 되어 있다면, 쫓아내는 것은 당신이 명령어를 보내는 MDS에만 
영향을 미친다는 점에 주의하기 바랍니다. 여러개의 활성 MDS 데몬이 있는 시스템에서는,
당신은 모든 활성화된 데몬에 쫓아내기 명령을 보내야 합니다. 
블랙리스팅이 적용되었을 때 (이것이 기본 설정입니다), 하나의 MDS에 쫓아내기 명령을
보내는 것으로 충분합니다. 왜냐하면 블랙리스트는 다른 MDS로 전파되기 때문입니다.

.. _background_blacklisting_and_osd_epoch_barrier:

배경: 블랙리스트와 OSD 에폭 배리어
==============================================

어떤 클라이언트가 블랙리스트에 들어가고 나면, 다른 클라이언트와 MDS 데몬이 
블랙리스트에 들어간 클라이언트가 접근하고 있었던 데이터 객체들을 액세스 
하기 전에, 최신의 OSDMap (블랙리스트 항목이 포함된)을 가지고 있게 해야 합니다.

내부적으로 "osdmap epoch barrier" 메커니즘에 의해 보장됩니다. 

이 배리어의 목적은 어떤 capability 를 나눠 줄 때 
